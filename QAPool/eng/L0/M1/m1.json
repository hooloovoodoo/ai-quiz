[
  {
  "question": "Which scenario best represents Artificial Narrow Intelligence (ANI)?",
  "answers": [
    "A translation system that excels at converting text between languages but cannot carry its skills over to unrelated tasks without task-specific training.",
    "An assistant that reaches human-level competence across diverse fields and flexibly masters new tasks without dedicated training.",
    "A superintelligence that outperforms humans in all areas and rapidly self-improves beyond human control.",
    "A thermostat that uses a fixed rule (if temperature > 30Â°C, turn on cooling) to control a room."
  ],
  "correct": "A translation system that excels at converting text between languages but cannot carry its skills over to unrelated tasks without task-specific training."
  },
  {
    "question": "Which statement best describes the containment (subset) relationships among Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL)?",
    "answers": [
      "AI contains ML, and ML contains DL.",
      "ML contains AI, and AI contains DL.",
      "DL contains ML, and ML contains AI.",
      "AI equals ML, and both contain DL."
    ],
    "correct": "AI contains ML, and ML contains DL."
  },
  {
    "question": "In the ANI/AGI/ASI capability taxonomy, a voice-enabled assistant can set reminders, answer routine questions, and translate short phrases, but cannot transfer its skills to unrelated domains without new training. Which level best describes this system?",
    "answers": [
      "Artificial Narrow Intelligence (ANI)",
      "Artificial General Intelligence (AGI)",
      "Artificial Super Intelligence (ASI)",
      "None of the above"
    ],
    "correct": "Artificial Narrow Intelligence (ANI)"
  },
  {
    "question": "A facility runs two climate control systems. System A uses engineer-defined IF/THEN rules; System B was trained on historical temperature - comfort data to predict settings. Which option correctly matches each system on (1) logic, (2) behavior, and (3) how updates are made?",
    "answers": [
      "System A: explicit rules; deterministic; update via code changes. System B: learned from data; probabilistic; update via retraining.",
      "System A: explicit rules; probabilistic; update via code changes. System B: learned from data; deterministic; update via retraining.",
      "System A: learned from data; deterministic; update via retraining. System B: explicit rules; probabilistic; update via code changes.",
      "System A: explicit rules; deterministic; update via retraining. System B: learned from data; probabilistic; update via code changes."
    ],
    "correct": "System A: explicit rules; deterministic; update via code changes. System B: learned from data; probabilistic; update via retraining."
  },
  {
    "question": "You train a neural network on 1 million labeled images using a weight - update procedure (e.g., stochastic gradient descent), then use it to classify new photos. In this setup, what is the algorithm?",
    "answers": [
      "The learned network with its final weights used for prediction",
      "The procedure that specifies how the weights are updated during training",
      "The dataset of 1 million labeled images used to teach the network",
      "The class labels the system produces for unseen photos"
    ],
    "correct": "The procedure that specifies how the weights are updated during training"
  },
  {
    "question": "Which statement describes a model in machine learning?",
    "answers": [
      "The result of training - the learned patterns that make predictions or decisions.",
      "The algorithmic procedure that defines how the system learns from data.",
      "The training configuration of hyperparameters such as learning rate and batch size.",
      "The loss function that scores errors and steers parameter updates during training."
    ],
    "correct": "The result of training - the learned patterns that make predictions or decisions."
  },
  {
    "question": "What does 'deep' refer to in Deep Learning?",
    "answers": [
      "The depth and complexity of data analysis performed",
      "Multiple layers of processing in neural networks",
      "The extreme complexity of the problem being solved",
      "The amount of data used"
    ],
    "correct": "Multiple layers of processing in neural networks"
  },
  {
    "question": "A team trains a vision model for weeks on thousands of labeled images using many GPUs. After release, the system answers in milliseconds. Which option correctly characterizes the training phase?",
    "answers": [
      "The compute-heavy stage where the model learns from data and updates its parameters",
      "The fast, per-request stage where the model applies what it already learned",
      "The post-launch period when end users interact with the system",
      "The evaluation step that measures accuracy on a held-out test set"
    ],
    "correct": "The compute-heavy stage where the model learns from data and updates its parameters"
  },
  {
    "question": "Which scenario best illustrates the inference phase of an AI system?",
    "answers": [
      "A deployed speech model converts a new voicemail to text using its current weights.",
      "A vision network adjusts its filters while training on labeled images to lower loss.",
      "A data pipeline tokenizes and normalizes text before feeding it to the model.",
      "Engineers modify hyperparameters and restart epochs to improve accuracy on validation data."
    ],
    "correct": "A deployed speech model converts a new voicemail to text using its current weights."
  },
  {
    "question": "Which AI paradigm focuses on generating new content - such as drafting product descriptions and producing matching images - from a single prompt? Choose the output paradigm, not the input modality.",
    "answers": [
      "Multimodal AI",
      "Generative AI",
      "Reinforcement Learning",
      "Predictive (Discriminative) AI"
    ],
    "correct": "Generative AI"
  },
  {
    "question": "A retailer is evaluating four AI capabilities. Which task most requires a generative approach rather than a predictive/discriminative one?",
    "answers": [
      "Write a product description from a short brief",
      "Generate a churn probability score for each customer",
      "Extract text from scanned invoices into a spreadsheet",
      "Classify incoming emails to route them by topic"
    ],
    "correct": "Write a product description from a short brief"
  },
  {
    "question": "Which task is explicitly listed in this module as an NLP application?",
    "answers": [
      "Producing a concise summary of a lengthy written report",
      "Converting a scanned paper document into editable digital text (OCR)",
      "Creating a new image from a natural-language prompt",
      "Transcribing a recorded meeting from speech audio into text"
    ],
    "correct": "Producing a concise summary of a lengthy written report"
  },
  {
    "question": "Which statement best describes a modern Large Language Model (LLM) and how it is trained?",
    "answers": [
      "A general-purpose generative model with billions of parameters, pre-trained on internet-scale unlabeled text using next-token prediction",
      "A general-purpose generative model with billions of parameters trained primarily through supervised learning on labeled instruction datasets to map prompts to answers",
      "A pre-trained next-token predictor over internet-scale data that delivers deterministic, task-specific outputs once deployed",
      "A compact, domain-limited classifier optimized for fixed tasks using small curated labeled datasets and hundreds of millions of parameters"
    ],
    "correct": "A general-purpose generative model with billions of parameters, pre-trained on internet-scale unlabeled text using next-token prediction"
  },
  {
    "question": "In large language models (LLMs), what does the term 'context window' refer to?",
    "answers": [
      "The maximum tokens the model considers from both the prompt and its own replies at once.",
      "The maximum number of parameters the model attention layers can examine during pre-training.",
      "Only the user's input tokens that the model reads before generating an answer.",
      "The time span of recent messages that the model prioritizes when responding."
    ],
    "correct": "The maximum tokens the model considers from both the prompt and its own replies at once."
  },
  {
    "question": "A model says, 'My knowledge is current through April 2023.' What does this most accurately indicate?",
    "answers": [
      "The most recent date included in its training data; events after that may be missing unless it uses external tools.",
      "The largest amount of text it can process in one go, which limits how much context it can consider.",
      "The point in a long conversation when earlier messages are dropped because the dialogue exceeds working memory.",
      "The model's public release or last deployment date, which determines how current its built-in knowledge is."
    ],
    "correct": "The most recent date included in its training data; events after that may be missing unless it uses external tools."
  },
  {
    "question": "Which scenario best illustrates the 'Garbage In, Garbage Out' principle in AI?",
    "answers": [
      "A hiring model trained on past resumes from a male-dominated workforce begins to systematically score women's resumes lower for similar qualifications.",
      "The team adds more GPUs and increases batch size; training finishes sooner, and accuracy rises without altering the training data.",
      "Engineers refactor the pipeline; by changing the training loop and optimizer settings, incorrectly labeled images in the dataset are corrected.",
      "The model's context window is expanded from 8k to 128k tokens, which stops it from hallucinating incorrect facts in lengthy responses, increasing the Input pool."
    ],
    "correct": "A hiring model trained on past resumes from a male-dominated workforce begins to systematically score women's resumes lower for similar qualifications."
  },
  {
    "question": "A company builds a spam filter that learns from many emails with user-provided 'spam'/'not spam' tags and then classifies new messages. Which learning approach does this most clearly exemplify?",
    "answers": [
      "Unsupervised Learning",
      "Semi-Supervised Learning",
      "Reinforcement Learning",
      "Supervised Learning"
    ],
    "correct": "Supervised Learning"
  },
  {
    "question": "A robot learns to navigate a warehouse by trying routes, earning points for fast deliveries and penalties for collisions, and gradually improves through trial and error. Which type of machine learning best fits this scenario?",
    "answers": [
      "Unsupervised Learning",
      "Deep Learning",
      "Reinforcement Learning",
      "Supervised Learning"
    ],
    "correct": "Reinforcement Learning"
  },
  {
    "question": "Which scenario demonstrates multimodal AI?",
    "answers": [
      "A classifier jointly trained on an article's headline and body to improve topic labeling and routing",
      "A multilingual assistant for support chats that reads and writes text only across all conversations",
      "An app that takes a photo and a spoken question, then replies in text and highlights regions on the image",
      "A vision system that fuses several camera feeds into one panorama to expand coverage and tracking"
    ],
    "correct": "An app that takes a photo and a spoken question, then replies in text and highlights regions on the image"
  },
  {
    "question": "In LLMs, a token is best described as:",
    "answers": [
      "A security credential for accessing the model",
      "A text unit for context limits, often smaller than a word",
      "A single character of text, like one letter, number or special character",
      "An entire word, regardless of length or language"
    ],
    "correct": "A text unit for context limits, often smaller than a word"
  },
  {
    "question": "A company trains a resume-screening model on 10 years of hiring data that underrepresents women and minorities. To mitigate GIGO-related bias in outcomes, which action is most effective?",
    "answers": [
      "Collect balanced, representative resumes and re-train, then validate fairness across demographic groups.",
      "Remove names and demographic fields (e.g., gender, race) but keep the original labels and splits unchanged.",
      "Add more resumes from the same decade to increase sample size and representativeness.",
      "Tune for higher overall accuracy on current validation data to ensure fair results."
    ],
    "correct": "Collect balanced, representative resumes and re-train, then validate fairness across demographic groups."
  },
  {
    "question": "A hospital trains a diagnosis model on a dataset dominated by one demographic group and deploys it for all patients. Which outcome is the most likely real-world consequence?",
    "answers": [
      "The model may show high overall accuracy while underperforming for underrepresented patients (e.g., more false negatives).",
      "Validation accuracy on the held-out set guarantees fairness across demographics, making subgroup errors unlikely.",
      "The model will debias itself during inference as it encounters more diverse patients, eliminating disparities without retraining.",
      "Scaling to a larger model typically removes training-data bias, leading to uniform performance across groups."
    ],
    "correct": "The model may show high overall accuracy while underperforming for underrepresented patients (e.g., more false negatives)."
  },
  {
    "question": "While chatting with a large language model, it confidently cites a specific research paper and URL, but when you check, neither exists. What is the most accurate term for this behavior?",
    "answers": [
      "Knowledge cutoff: the model's training stopped earlier, so the info is outdated, not invented",
      "Context window limit: it forgot prior details and filled the gaps with a guess",
      "Hallucination: it generated plausible but nonexistent citations and content",
      "Bias in training data: skewed examples led it to produce distorted references"
    ],
    "correct": "Hallucination: it generated plausible but nonexistent citations and content"
  },
  {
    "question": "In modern AI practice, which approach is most appropriate for classifying emails as spam or not spam?",
    "answers": [
      "Generative models that learn to produce realistic email text",
      "Symbolic rule-based filters with hand-crafted patterns and keywords",
      "Supervised discriminative ML trained on labeled spam examples",
      "Unsupervised clustering that groups emails without using labels"
    ],
    "correct": "Supervised discriminative ML trained on labeled spam examples"
  },
  {
    "question": "What is Computer Vision in AI?",
    "answers": [
      "AI that only labels objects and scenes and cannot create images",
      "AI for rendering realistic 3D graphics and game simulations",
      "AI that both interprets images/video and creates new visuals",
      "AI that enhances photos and videos without interpreting them"
    ],
    "correct": "AI that both interprets images/video and creates new visuals"
  },
  {
    "question": "Which description best matches AGI (Artificial General Intelligence)?",
    "answers": [
      "A system that learns and applies knowledge across unrelated tasks at human level; not yet achieved.",
      "A model that excels at one task - like translation or Go - but cannot transfer skills between domains.",
      "A capability already achieved in labs and partly shipped in consumer smartphones today.",
      "An intelligence that surpasses humans in every domain and is purely theoretical at this point."
    ],
    "correct": "A system that learns and applies knowledge across unrelated tasks at human level; not yet achieved."
  },
  {
    "question": "In deep learning, what does the term 'deep' specifically refer to?",
    "answers": [
      "Training on very large datasets, making the learning process deep in data volume",
      "Stacking multiple learnable layers to build hierarchical feature representations across stages",
      "Capturing deeper semantic meaning even with a single layer, not the number of layers",
      "Freezing early layers and training only a final classifier during the learning process"
    ],
    "correct": "Stacking multiple learnable layers to build hierarchical feature representations across stages"
  },
  {
    "question": "Why should practitioners be aware of a model's context window when working with long chats or documents?",
    "answers": [
      "It sets the model's knowledge cutoff date, so staying within it keeps information up to date",
      "Exceeding it can cause earlier turns to be dropped, so long inputs may need chunking to preserve context",
      "It controls how many parameters the model activates at inference, which drives speed and cost",
      "It limits how far into training data the model can recall facts, affecting retrieval from older data sources"
    ],
    "correct": "Exceeding it can cause earlier turns to be dropped, so long inputs may need chunking to preserve context"
  }
]
