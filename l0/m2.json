[
    {
      "question": "What is AI Bias?",
      "answers": [
        "When AI systems favor newer technology",
        "When systems make unfair decisions based on protected characteristics",
        "When AI prefers certain programming languages",
        "When systems work faster for some users"
      ],
      "correct": "When systems make unfair decisions based on protected characteristics"
    },
    {
      "question": "Which of the following is a source of bias in AI systems?",
      "answers": [
        "Historical discrimination reflected in data",
        "Using too much electricity",
        "Having too many users",
        "Running on old hardware"
      ],
      "correct": "Historical discrimination reflected in data"
    },
    {
      "question": "What are AI hallucinations?",
      "answers": [
        "When AI sees things that aren't there",
        "When AI dreams while processing",
        "When systems generate incorrect information while presenting it confidently as fact",
        "When AI creates artistic images"
      ],
      "correct": "When systems generate incorrect information while presenting it confidently as fact"
    },
    {
      "question": "Why do AI hallucinations happen?",
      "answers": [
        "AI gets tired from too much work",
        "AI predicts 'likely' responses, not 'true' ones",
        "The computer overheats",
        "The internet connection is slow"
      ],
      "correct": "AI predicts 'likely' responses, not 'true' ones"
    },
    {
      "question": "What happened with Amazon's resume screening AI system?",
      "answers": [
        "It worked perfectly and was adopted globally",
        "It downgraded resumes containing 'women's' and penalized all-women colleges",
        "It only accepted resumes in PDF format",
        "It was too expensive to maintain"
      ],
      "correct": "It downgraded resumes containing 'women's' and penalized all-women colleges"
    },
    {
      "question": "How long did Microsoft's Tay chatbot last before being shut down?",
      "answers": [
        "1 week",
        "1 month",
        "24 hours",
        "1 year"
      ],
      "correct": "24 hours"
    },
    {
      "question": "What is the 'Black Box' problem in AI?",
      "answers": [
        "AI systems are painted black",
        "We can't see inside to understand how AI reaches its conclusions",
        "AI systems are stored in black containers",
        "The screen goes black when AI is processing"
      ],
      "correct": "We can't see inside to understand how AI reaches its conclusions"
    },
    {
      "question": "Which is NOT a core principle of Ethical AI?",
      "answers": [
        "Transparency",
        "Fairness",
        "Profitability",
        "Accountability"
      ],
      "correct": "Profitability"
    },
    {
      "question": "What does 'Human in the Loop' mean?",
      "answers": [
        "Humans run in circles around AI",
        "Maintaining meaningful human oversight of AI systems",
        "Humans are trapped by AI",
        "AI systems are shaped like loops"
      ],
      "correct": "Maintaining meaningful human oversight of AI systems"
    },
    {
      "question": "What are guardrails in AI?",
      "answers": [
        "Physical barriers around computers",
        "Safety mechanisms that prevent AI from generating harmful content",
        "Rails that guide AI robots",
        "Security guards for data centers"
      ],
      "correct": "Safety mechanisms that prevent AI from generating harmful content"
    },
    {
      "question": "What type of bias occurs when some groups are underrepresented in training data?",
      "answers": [
        "Historical bias",
        "Representation bias",
        "Measurement bias",
        "Speed bias"
      ],
      "correct": "Representation bias"
    },
    {
      "question": "What should you do before using someone's photo in AI tools?",
      "answers": [
        "Check if the photo is high quality",
        "Get their permission",
        "Make sure it's in color",
        "Nothing special required"
      ],
      "correct": "Get their permission"
    },
    {
      "question": "What does PII stand for?",
      "answers": [
        "Public Internet Information",
        "Private Internal Intelligence",
        "Personally Identifiable Information",
        "Professional IT Infrastructure"
      ],
      "correct": "Personally Identifiable Information"
    },
    {
      "question": "Which organization created the Ethically Aligned Design initiative?",
      "answers": [
        "Google",
        "IEEE Standards",
        "Microsoft",
        "Amazon"
      ],
      "correct": "IEEE Standards"
    },
    {
      "question": "What is a real consequence of AI hallucinations?",
      "answers": [
        "Computers exploding",
        "Lawyers citing non-existent cases in court",
        "AI refusing to work",
        "Screens turning purple"
      ],
      "correct": "Lawyers citing non-existent cases in court"
    },
    {
      "question": "What type of guardrail blocks harmful requests before processing?",
      "answers": [
        "Output Filters",
        "Input Filters",
        "Speed Filters",
        "Color Filters"
      ],
      "correct": "Input Filters"
    },
    {
      "question": "Which is an example of biometric personal data?",
      "answers": [
        "Email address",
        "Fingerprints",
        "Phone number",
        "Home address"
      ],
      "correct": "Fingerprints"
    },
    {
      "question": "What happened to Microsoft's Tay chatbot?",
      "answers": [
        "It became the world's best chatbot",
        "It was fed racist content and became offensive",
        "It solved world hunger",
        "It won a Nobel Prize"
      ],
      "correct": "It was fed racist content and became offensive"
    },
    {
      "question": "How should you treat AI-generated information?",
      "answers": [
        "Always trust it completely",
        "Never use it at all",
        "Use as starting point, not final answer",
        "Share it without verification"
      ],
      "correct": "Use as starting point, not final answer"
    },
    {
      "question": "What is UNESCO's role in AI ethics?",
      "answers": [
        "Building AI systems",
        "Selling AI software",
        "Providing global ethical standards for AI",
        "Training AI models"
      ],
      "correct": "Providing global ethical standards for AI"
    },
    {
      "question": "What should you NOT input into public AI tools?",
      "answers": [
        "General questions",
        "Sensitive, confidential, or PII",
        "Creative writing prompts",
        "Math problems"
      ],
      "correct": "Sensitive, confidential, or PII"
    },
    {
      "question": "What is data minimization?",
      "answers": [
        "Making data files smaller",
        "Deleting all data",
        "Only providing AI the minimum information needed",
        "Using small fonts"
      ],
      "correct": "Only providing AI the minimum information needed"
    },
    {
      "question": "What is aggregation bias?",
      "answers": [
        "When AI aggregates too slowly",
        "When one-size-fits-all models ignore specific groups",
        "When data is too aggregated",
        "When AI refuses to aggregate"
      ],
      "correct": "When one-size-fits-all models ignore specific groups"
    },
    {
      "question": "What privacy challenge exists with smart speakers?",
      "answers": [
        "They're too loud",
        "They may record private conversations",
        "They use too much electricity",
        "They're too expensive"
      ],
      "correct": "They may record private conversations"
    },
    {
      "question": "What does accountability mean in Ethical AI?",
      "answers": [
        "Counting AI systems",
        "Making AI do accounting",
        "Clear responsibility for AI actions",
        "Teaching AI mathematics"
      ],
      "correct": "Clear responsibility for AI actions"
    },
    {
      "question": "Why was Amazon's resume screening AI scrapped?",
      "answers": [
        "It was too slow",
        "It couldn't guarantee bias elimination",
        "It was too expensive",
        "It required too much storage"
      ],
      "correct": "It couldn't guarantee bias elimination"
    },
    {
      "question": "What is a challenge with AI guardrails?",
      "answers": [
        "They're too colorful",
        "Balancing safety with usefulness",
        "They're too heavy",
        "They rust easily"
      ],
      "correct": "Balancing safety with usefulness"
    },
    {
      "question": "What should you do with AI outputs before relying on them?",
      "answers": [
        "Print them out",
        "Always review and verify",
        "Delete them immediately",
        "Share with everyone"
      ],
      "correct": "Always review and verify"
    },
    {
      "question": "Which is an example of behavioral personal data?",
      "answers": [
        "Hair color",
        "Purchase history",
        "Height",
        "Blood type"
      ],
      "correct": "Purchase history"
    },
    {
      "question": "What type of content filtering did Microsoft's Tay lack?",
      "answers": [
        "Image filtering",
        "Adequate content filtering against harmful messages",
        "Audio filtering",
        "Video filtering"
      ],
      "correct": "Adequate content filtering against harmful messages"
    },
    {
      "question": "What is a prevention strategy for AI hallucinations?",
      "answers": [
        "Never use AI",
        "Cross-reference multiple sources",
        "Use AI only on Mondays",
        "Type faster"
      ],
      "correct": "Cross-reference multiple sources"
    },
    {
      "question": "What happens when collection methods favor certain groups?",
      "answers": [
        "Speed bias",
        "Measurement bias",
        "Color bias",
        "Size bias"
      ],
      "correct": "Measurement bias"
    },
    {
      "question": "What is the purpose of Output Filters in guardrails?",
      "answers": [
        "To make output colorful",
        "To screen generated content",
        "To speed up processing",
        "To reduce file size"
      ],
      "correct": "To screen generated content"
    },
    {
      "question": "What should you be transparent about when using AI?",
      "answers": [
        "Your password",
        "If AI was used significantly in creating content",
        "Your salary",
        "Your home address"
      ],
      "correct": "If AI was used significantly in creating content"
    },
    {
      "question": "Why is the Black Box problem important?",
      "answers": [
        "Black boxes are expensive",
        "Hard to trust unexplained decisions",
        "Black is an unpopular color",
        "Boxes take up space"
      ],
      "correct": "Hard to trust unexplained decisions"
    },
    {
      "question": "What does fairness mean in Ethical AI principles?",
      "answers": [
        "AI works at the same speed for everyone",
        "Equal treatment for all groups",
        "AI costs the same for everyone",
        "AI uses the same colors for everyone"
      ],
      "correct": "Equal treatment for all groups"
    },
    {
      "question": "What is a key lesson from the Microsoft Tay incident?",
      "answers": [
        "AI should never use Twitter",
        "AI systems exposed to public input need robust protection",
        "Chatbots should only speak English",
        "Microsoft should stop making AI"
      ],
      "correct": "AI systems exposed to public input need robust protection"
    }
  ]
